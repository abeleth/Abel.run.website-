ðŸ—½Journey in DevOps.
=======
ðŸš€"Engineering seamless solutions, automating excellence, and driving innovationâ€”one deployment at a time. Pushing the limits of what's possible in the ultimate DevOps career. #DevOpsDriven"

<a href="https://github.com/abeleth/Abel.run.website-/blob/main/Devops1/README.md">
  <img src="https://github.com/user-attachments/assets/796643bc-2a54-449b-ba17-ffef71b8a2c6" alt="Devops1" width="100" height="50"> 
</a>

[DevOps](Devops1/README.md)

Git is essential for DevOps engineers as it provides robust version control, enabling efficient collaboration and code management across distributed teams. It tracks changes in application code, scripts, and infrastructure-as-code (IaC) files, ensuring transparency, rollback capabilities, and auditability. Git integrates seamlessly with CI/CD pipelines, automating code builds, tests, and deployments to streamline workflows. Its branching and merging features support parallel development, while pull requests enable code reviews to maintain quality. Additionally, Git ensures redundancy through distributed repositories, aiding disaster recovery. By fostering consistency, automation, and collaboration, Git is a cornerstone of modern DevOps practices.

<a href="https://github.com/abeleth/Abel.run.website-/blob/main/git/README.md">
  <img src="https://github.com/user-attachments/assets/19155cff-6ae9-4137-99ca-e0ed502c51e3" alt="git1" width="100" height="50"> 
</a>

[Git](git1/README.md)


AWS (Amazon Web Services) is a leading cloud computing platform that provides on-demand, scalable infrastructure and services to support diverse applications. It offers a wide range of tools, including computing power (EC2), storage (S3), databases (RDS, DynamoDB), networking, and machine learning. AWS is critical for DevOps workflows, with services like CloudFormation and Terraform for Infrastructure as Code, CodePipeline for CI/CD automation, and CloudWatch for monitoring and logging. Its container services (ECS, EKS, and Fargate) and serverless computing (Lambda) enable modern, agile application development. By delivering flexibility, reliability, and cost-effectiveness, AWS empowers businesses to innovate and scale efficiently.


<a href="https://github.com/abeleth/Abel.run.website-/blob/main/aws/README.md">
  <img src="https://github.com/user-attachments/assets/67b9e778-314c-4210-b769-2077b2f5351f" alt="aws" width="100" height="50"> 
</a>

[AWS](aws/README.md)

Google Cloud Platform (GCP) is a robust cloud computing platform that provides scalable, secure, and high-performance infrastructure and services for modern applications. Known for its advanced data analytics, AI, and machine learning tools like BigQuery and TensorFlow, GCP excels in handling large-scale data processing and innovation. It supports DevOps workflows with tools like Cloud Build for CI/CD, Deployment Manager and Terraform for Infrastructure as Code, and Stackdriver for monitoring and logging. GCP also offers versatile container orchestration through Google Kubernetes Engine (GKE), leveraging its leadership in Kubernetes development. With global infrastructure, strong integration with open-source tools, and a commitment to sustainability, GCP is ideal for developers and businesses seeking flexibility and innovation in the cloud.

<a href="https://github.com/abeleth/Abel.run.website-/blob/main/Google Cloud/README.md">
  <img src="https://github.com/user-attachments/assets/6a9b0a99-25ef-41cf-82e7-ad4dfaea8592" alt="Google cloud" width="100" height="50"> 
</a>

[Google](GoogleCloud/README.md)


Linux is a powerful, open-source operating system kernel that forms the foundation for many operating systems, widely used in servers, desktops, mobile devices, and embedded systems. Renowned for its stability, security, and flexibility, Linux is essential in DevOps, powering cloud servers, containers, and virtual machines. It supports a wide range of tools and programming languages, making it a favorite for developers and system administrators. With robust command-line utilities, package managers, and a vibrant open-source community, Linux enables efficient system management, automation, and troubleshooting. Its modular design and open-source nature make it highly customizable, ensuring it meets diverse operational and development needs.

<a href="https://github.com/abeleth/Abel.run.website-/blob/main/Linux/README.md">
  <img src="https://github.com/user-attachments/assets/a369b54a-29a7-4e54-93d7-02771eb0627c" alt="Linux" width="100" height="50"> 
</a>

[Linux](Linux/README.md)

Virtualization is a technology that enables the creation of multiple virtual environments on a single physical hardware system, allowing resources like CPU, memory, and storage to be abstracted and allocated efficiently. It is a cornerstone of modern IT infrastructure, enabling the deployment of virtual machines (VMs) that run isolated operating systems and applications. Virtualization enhances resource utilization, reduces hardware costs, and simplifies management by consolidating workloads. It supports scalability, disaster recovery, and testing environments, making it essential for cloud computing and DevOps practices. Popular virtualization platforms include VMware, Hyper-V, and open-source solutions like KVM and VirtualBox.

<a href="https://github.com/abeleth/Abel.run.website-/blob/main/Virtualization/README.md">
  <img src="https://github.com/user-attachments/assets/ce3efb3a-cdd3-4844-8cc2-7a46887c0048" alt="Virtualization" width="100" height="50"> 
</a>

[Virtualization](Virtualization)

Terraform is an open-source Infrastructure as Code (IaC) tool that allows DevOps engineers to define, provision, and manage infrastructure resources using declarative configuration files. Developed by HashiCorp, it supports a wide range of cloud providers, such as AWS, Azure, Google Cloud, and on-premises systems. With Terraform, users can automate infrastructure provisioning, ensure consistency across environments, and version control infrastructure configurations. Its modular approach and reusable configurations enable scalability and collaboration. Terraform also supports state management, which tracks the current infrastructure state, and enables safe and efficient updates and changes to infrastructure resources, making it a crucial tool for modern DevOps practices.

<a href="https://github.com/abeleth/Abel.run.website-/blob/main/Terraform/README.md">
  <img src="https://github.com/user-attachments/assets/cc3a69fd-dfea-4085-9cbe-2c397069c193" alt="Terraform" width="100" height="50"> 
</a>

[Terraform](Terraform/README.md)

Kubernetes is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications. In DevOps, Kubernetes is crucial for managing microservices-based architectures, enabling teams to efficiently deploy and operate containers in production environments. It provides features like automated scaling, self-healing, load balancing, and rolling updates, which streamline the management of application workloads. Kubernetes integrates seamlessly with CI/CD pipelines, enhancing DevOps workflows by automating the deployment of code changes, improving infrastructure efficiency, and ensuring high availability. With its declarative configuration model and extensive ecosystem, Kubernetes is central to achieving continuous delivery and rapid application updates in modern cloud-native environments.

<a href="https://github.com/abeleth/Abel.run.website-/blob/main/Kubernetes/README.md">
  <img src="https://github.com/user-attachments/assets/6566fa12-f271-4dbb-b60a-db404ebbda27" alt="Kubernetes" width="100" height="50"> 
</a>

[Kubernetes](Kubernetes/README.md)


Python is a versatile, high-level programming language widely used in DevOps for automation, scripting, and system administration tasks. Its simplicity and readability make it ideal for writing automation scripts to manage infrastructure, deploy applications, and configure systems. In DevOps, Python is often used in conjunction with tools like Ansible for configuration management, Jenkins for CI/CD pipeline automation, and Docker for container management. With powerful libraries such as Paramiko for SSH connectivity, Boto3 for AWS integration, and Fabric for task automation, Python enables DevOps engineers to streamline workflows, automate repetitive tasks, and manage cloud resources efficiently. Its strong community and vast ecosystem of libraries make Python a go-to language for enhancing productivity in DevOps practices.

<a href="https://github.com/abeleth/Abel.run.website-/blob/main/Python1/README.md">
  <img src="https://github.com/user-attachments/assets/4de84534-ce4c-48fc-a44d-2b979b6b95ff" alt="Kubernetes" width="100" height="50"> 
</a>

[Python](Python1/README.md)


<a href="https://github.com/abeleth/Abel.run.website-/blob/main/Testing/README.md">
  <img src="https://github.com/user-attachments/assets/5b7c8d07-8fb6-45bb-aed6-c17ea3c893c2" alt="Testing" width="100" height="50"> 
</a>

[Testing](Testing/README.md)


# Installation

# Git on **Linux Ubuntu**

![image.png](attachment:19651e64-d772-4757-a46d-3c0eab097396:image.png)

```yaml
sudo apt update && sudo apt install -y git
git --version

```

# AWS on **Linux Ubuntu**

![image.png](attachment:0a1cfba0-114f-43ee-902f-4264ef98ae9c:image.png)

```yaml
aws --version
sudo apt  install awscli
aws --version

```

# Docker on **Linux Ubuntu**

![image.png](attachment:da0fffa3-5c8b-46c4-81ba-efbdd0fbb735:image.png)

```yaml
sudo apt update
sudo apt install -y [docker.io](http://docker.io/)
sudo systemctl start docker
sudo systemctl enable docker
docker --version
```

docker login faild errorr on jenkins

```yaml
sudo su
sudo usermod -aG docker jenkins
sudo systemctl restart jenkins
```

# Java on **Linux Ubuntu**

![image.png](attachment:84e135d1-f986-47ba-9e7c-72a7a3e45095:image.png)

```yaml
java -version
sudo apt install openjdk-21-jre-headless
java -version
```

# Python on **Linux Ubuntu**

![image.png](attachment:e43596a5-1ac8-4732-ae6c-50aa671660ad:image.png)

```yaml
sudo apt update && sudo apt install -y python3 python3-pip python3-venv
python3 --version
sudo apt install python3-pip
pip3 --version

```

### **Verify Installation:**

Run these commands to check if the tools are installed properly:

```yaml
git --version
docker --version
terraform --version
aws --version
kubectl version --client
```

# Jenkins on **Linux Ubuntu**

![image.png](attachment:3f13c89c-3f02-4515-a334-09b6afccecfd:image.png)

```yaml
sudo apt update
sudo apt install openjdk-21-jdk
java -version
sudo apt update
sudo systemctl start jenkins
cat /Users/$(whoami)/. jenkins/secrets/initialAdminPassword
```

passwordâ†’

> [http://localhost:](http://localhost/)8080
> 

# **Install Jenkins for Automation:**

- Install Jenkins on the EC2 instance to automate deployment: Install Java

```
sudo apt update
sudo apt install fontconfig openjdk-17-jre
java -version
openjdk version "17.0.8" 2023-07-18
OpenJDK Runtime Environment (build 17.0.8+7-Debian-1deb12u1)
OpenJDK 64-Bit Server VM (build 17.0.8+7-Debian-1deb12u1, mixed mode, sharing)

#jenkins
sudo wget -O /usr/share/keyrings/jenkins-keyring.asc \
https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key
echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \
https://pkg.jenkins.io/debian-stable binary/ | sudo tee \
/etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt-get update
sudo apt-get install jenkins
sudo systemctl start jenkins
sudo systemctl enable jenkins
```

```yaml
sudo service jenkins status
```

- Access Jenkins in a web browser using the public IP of your EC2 instance.
    
    publicIp:8080
    

sudo cat   `/var/lib/jenkins/secrets/initialAdminPassword`

cat /Users/$(whoami)/. jenkins/secrets/initialAdminPassword

 **Monitoring**

# **Install Prometheus and Grafana:**

![image.png](attachment:515ff146-2fc6-4b37-95e1-27e84ae3d3f1:image.png)

Set up Prometheus and Grafana to monitor your application.

**Installing Prometheus:**

First, create a dedicated Linux user for Prometheus and download Prometheus:

```
sudo useradd --system --no-create-home --shell /bin/false prometheus
wget https://github.com/prometheus/prometheus/releases/download/v2.47.1/prometheus-2.47.1.linux-amd64.tar.gz
```

Extract Prometheus files, move them, and create directories:

```
tar -xvf prometheus-2.47.1.linux-amd64.tar.gz
cd prometheus-2.47.1.linux-amd64/
sudo mkdir -p /data /etc/prometheus
sudo mv prometheus promtool /usr/local/bin/
sudo mv consoles/ console_libraries/ /etc/prometheus/
sudo mv prometheus.yml /etc/prometheus/prometheus.yml
```

Set ownership for directories:

```
sudo chown -R prometheus:prometheus /etc/prometheus/ /data/
```

Create a systemd unit configuration file for Prometheus:

```
sudo nano /etc/systemd/system/prometheus.service
```

Add the following content to theÂ `prometheus.service`Â file:

```
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

StartLimitIntervalSec=500
StartLimitBurst=5

[Service]
User=prometheus
Group=prometheus
Type=simple
Restart=on-failure
RestartSec=5s
ExecStart=/usr/local/bin/prometheus \
  --config.file=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path=/data \
  --web.console.templates=/etc/prometheus/consoles \
  --web.console.libraries=/etc/prometheus/console_libraries \
  --web.listen-address=0.0.0.0:9090 \
  --web.enable-lifecycle

[Install]
WantedBy=multi-user.target

```

Verify Prometheus's status:

```
sudo systemctl enable prometheus
sudo systemctl start prometheus
```

```
sudo systemctl status prometheus
```

# Grafana

![image.png](attachment:85444dd8-bfdc-43f4-b7f6-c5254f60343d:image.png)

**Install Grafana on Ubuntu 22.04 and Set it up to Work with Prometheus**

**Step 1: Install Dependencies:**

First, ensure that all necessary dependencies are installed:

```
sudo apt-get update
sudo apt-get install -y apt-transport-https software-properties-common
```

**Step 2: Add the GPG Key:**

Add the GPG key for Grafana:

```
wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
```

**Step 3: Add Grafana Repository:**

Add the repository for Grafana stable releases:

```
echo "deb https://packages.grafana.com/oss/deb stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
```

**Step 4: Update and Install Grafana:**

Update the package list and install Grafana:

```
sudo apt-get update
sudo apt-get -y install grafana
```

**Step 5: Enable and Start Grafana Service:**

To automatically start Grafana after a reboot, enable the service:

```
sudo systemctl enable grafana-server
```

Then, start Grafana:

```
sudo systemctl start grafana-server
```

**Step 6: Check Grafana Status:**

Verify the status of the Grafana service to ensure it's running correctly:

```
sudo systemctl status grafana-server
```

**Step 7: Access Grafana Web Interface:**

Open a web browser and navigate to Grafana using your server's IP address. The default port for Grafana is 3000. For example:

`http://<your-server-ip>:3000`

# **Kubernetes**

![image.png](attachment:b6317d53-1ce3-45ad-b755-76841a3c7528:image.png)

**Create Kubernetes Cluster with Nodegroups**

In this phase, you'll set up a Kubernetes cluster with node groups. This will provide a scalable environment to deploy and manage your applications.

**Monitor Kubernetes with Prometheus**

Prometheus is a powerful monitoring and alerting toolkit, and you'll use it to monitor your Kubernetes cluster. Additionally, you'll install the node exporter using Helm to collect metrics from your cluster nodes.

**Install Node Exporter using Helm**

To begin monitoring your Kubernetes cluster, you'll install the Prometheus Node Exporter. This component allows you to collect system-level metrics from your cluster nodes. Here are the steps to install the Node Exporter using Helm:

1. Add the Prometheus Community Helm repository:
    
    ```
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    ```
    
2. Create a Kubernetes namespace for the Node Exporter:
    
    ```
    kubectl create namespace prometheus-node-exporter
    ```
    
3. Install the Node Exporter using Helm:
    
    ```
    helm install prometheus-node-exporter prometheus-community/prometheus-node-exporter --namespace prometheus-node-exporter
    ```
    

Add a Job to Scrape Metrics on nodeip:9001/metrics in prometheus.yml:

Update your Prometheus configuration (prometheus.yml) to add a new job for scraping metrics from nodeip:9001/metrics. You can do this by adding the following configuration to your prometheus.yml file:

```
  - job_name: 'Netflix'
    metrics_path: '/metrics'
    static_configs:
      - targets: ['node1Ip:9100']

```

Replace 'your-job-name' with a descriptive name for your job. The static_configs section specifies the targets to scrape metrics from, and in this case, it's set to nodeip:9001.

### **Install Ansible (If Not Installed)**

![image.png](attachment:37f898d9-7cd8-43d8-9350-4008f9ed35cd:image.png)

```bash

sudo apt update

sudo apt update && sudo apt install ansible -y

```

### **Check Version**

```bash
b
ansible --version

```

# DataDog

![image.png](attachment:3bf04c67-99d7-474f-b152-8b3a4b22e251:image.png)

To install Datadog on a Linux Ubuntu system, use the following command:

```bash

DD_API_KEY=<your_datadog_api_key> sudo -E bash -c "$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)"

```

### Steps:

1. Replace `<your_datadog_api_key>` with your actual Datadog API key. You can find this in your Datadog account under **Integrations > APIs**.
2. This command:
    - Downloads the Datadog installation script.
    - Executes the script to install the Datadog Agent on your system.

After installation, verify that the Datadog agent is running with:














